# Nemo Server

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-24.0+-blue.svg)](https://www.docker.com/)
[![CUDA](https://img.shields.io/badge/CUDA-12.6+-green.svg)](https://developer.nvidia.com/cuda-downloads)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**AI-Powered Conversational Memory & Transcription System**

A microservices-based platform that provides real-time speech transcription, speaker diarization, emotion analysis, semantic memory search, and AI-powered conversational responses. Built for smart glasses and voice-first applications.

---

## ğŸ¯ What It Does

Nemo Server transforms conversations into searchable, analyzable knowledge:

1. **Transcribe**: Real-time speech-to-text with speaker identification
2. **Analyze**: Emotion detection and audio quality metrics  
3. **Remember**: Semantic search across all conversations
4. **Respond**: AI assistant with full conversational context

Perfect for:
- Meeting transcription and analysis
- Smart glasses (AR/VR) voice interfaces
- Personal memory augmentation
- Conversational AI applications
- Voice-controlled systems

---

## ğŸ—ï¸ Architecture

### Microservices Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚ (Flutter App, Web Browser)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway (Port 8000)                                     â”‚
â”‚  â€¢ Authentication & Sessions                                 â”‚
â”‚  â€¢ Request Routing                                           â”‚
â”‚  â€¢ Frontend Serving                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚       â”‚       â”‚       â”‚        â”‚
    â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Transâ”‚ â”‚Emo â”‚ â”‚ RAG  â”‚ â”‚Gemma â”‚ â”‚    GPU    â”‚
    â”‚criptâ”‚ â”‚tionâ”‚ â”‚Searchâ”‚ â”‚  AI  â”‚ â”‚Coordinatorâ”‚
    â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Shared GPU
         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
         â”‚  GPU 0    â”‚
         â”‚ (NVIDIA)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Infrastructure:
  â€¢ Redis (Pub/Sub, Caching, Locking)
  â€¢ PostgreSQL (Task Queue)
  â€¢ Encrypted SQLite (User Data, Transcripts)
```

### Service Breakdown

| Service | Port | Purpose | GPU | Key Tech |
|---------|------|---------|-----|----------|
| **API Gateway** | 8000 | Auth, routing, frontend | No | FastAPI, SQLCipher |
| **Transcription** | 8003 | Speech-to-text, diarization | Yes* | NeMo, PyTorch |
| **Emotion** | 8005 | Sentiment analysis | No | Transformers |
| **RAG** | 8004 | Semantic search | No | FAISS, Sentence Transformers |
| **Gemma AI** | 8001 | LLM chat responses | Yes* | llama.cpp, Gemma 3 |
| **GPU Coordinator** | 8002 | GPU sharing | No | Redis, PostgreSQL |

*GPU is dynamically shared via coordinator

---

## âœ¨ Key Features

### ğŸ™ï¸ Advanced Transcription
- **Models**: NVIDIA Parakeet RNNT (600M params)
- **Speaker Diarization**: Automatic multi-speaker detection
- **Speaker Verification**: Match against enrolled voice profiles
- **Voice Activity Detection**: Intelligent speech segmentation
- **Real-time Processing**: Sub-second latency per chunk

### ğŸ˜Š Emotion Analysis
- **6 Emotions**: Joy, sadness, anger, fear, surprise, neutral
- **Confidence Scores**: Per-segment sentiment analysis
- **Fast**: <100ms per segment
- **Model**: DistilRoBERTa-base

### ğŸ” Semantic Memory Search
- **Natural Language Queries**: "What did Sarah say about the deadline?"
- **Vector Search**: FAISS-powered similarity search
- **Rich Filtering**: By speaker, date, emotion
- **Cross-Transcript**: Search entire conversation history

### ğŸ¤– AI Assistant (Gemma 3)
- **64K Context Window**: Long conversation memory
- **RAG-Enhanced**: Automatic context injection from memories
- **GPU Shared**: Dynamic GPU coordination with transcription
- **Streaming**: Token-by-token response streaming

### ğŸ” Enterprise Security
- **Encrypted Storage**: SQLCipher for sensitive data
- **JWT Authentication**: Service-to-service security
- **Replay Protection**: Request ID tracking
- **Session Management**: Secure cookie-based sessions
- **Docker Secrets**: No credentials in environment vars

### ğŸš€ GPU Coordination
- **Single GPU Support**: Intelligent sharing between services
- **Pause/Resume**: Sub-second context switching
- **No Conflicts**: Redis-based distributed locking
- **Automatic Fallback**: Graceful degradation on failures

---

## ğŸš€ Quick Start

### Prerequisites
- **GPU**: NVIDIA GPU with 8GB+ VRAM (recommended)
- **CUDA**: 12.6+ with cuDNN
- **Docker**: 24.0+ with Docker Compose
- **RAM**: 16GB+ system memory

### 1. Clone Repository
```bash
git clone https://github.com/pruittcolon/NeMo_Server.git
cd NeMo_Server
```

### 2. Setup Secrets
```bash
# Generate secure secrets
cd docker/secrets

# Create random keys
openssl rand -base64 32 > session_key
openssl rand -base64 32 > jwt_secret
openssl rand -base64 32 > users_db_key
openssl rand -base64 32 > rag_db_key

# Database credentials
echo "nemo_user" > postgres_user
openssl rand -base64 16 > postgres_password
openssl rand -base64 16 > redis_password

# Get Hugging Face token (optional, for model downloads)
echo "hf_your_token_here" > huggingface_token
```

### 3. Download Models
```bash
# Gemma 3 model (required for AI chat)
mkdir -p models
cd models
wget https://huggingface.co/unsloth/gemma-3-4b-it-GGUF/resolve/main/gemma-3-4b-it-UD-Q4_K_XL.gguf

# NeMo models download automatically on first run
# Emotion model downloads automatically
```

### 4. Build llama-cpp-python Wheel (for GPU support)
```bash
# This must be done on your host machine with CUDA
CMAKE_ARGS="-DGGML_CUDA=on" pip wheel llama-cpp-python==0.3.16 \
  --wheel-dir=./docker/wheels/ \
  --no-binary llama-cpp-python

# Or use pre-built wheel if compatible with your CUDA version
```

### 5. Start Services
```bash
# Start all services
./start.sh

# Or use docker compose directly
cd docker
docker compose up -d
```

### 6. Access Web Interface
```bash
# Browser opens automatically, or visit:
open http://localhost:8000

# Default credentials:
# Username: admin
# Password: (set during first run or via API)
```

---

## ğŸ“ Project Structure

```
Nemo_Server/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ start.sh                  # Startup script
â”œâ”€â”€ .gitignore               # Git ignore rules
â”‚
â”œâ”€â”€ docker/                   # Docker configuration
â”‚   â”œâ”€â”€ docker-compose.yml   # Service orchestration
â”‚   â”œâ”€â”€ Dockerfile.*         # Service-specific builds
â”‚   â”œâ”€â”€ secrets/             # Encrypted credentials (gitignored)
â”‚   â””â”€â”€ wheels/              # Pre-built Python wheels
â”‚
â”œâ”€â”€ services/                 # Microservices
â”‚   â”œâ”€â”€ api-gateway/         # Main entry point
â”‚   â”œâ”€â”€ transcription-service/  # Speech-to-text
â”‚   â”œâ”€â”€ emotion-service/     # Sentiment analysis
â”‚   â”œâ”€â”€ rag-service/         # Semantic search
â”‚   â”œâ”€â”€ gemma-service/       # AI chat
â”‚   â””â”€â”€ queue-service/       # GPU coordinator
â”‚
â”œâ”€â”€ shared/                   # Shared Python modules
â”‚   â”œâ”€â”€ auth/                # Authentication
â”‚   â”œâ”€â”€ crypto/              # Encryption utilities
â”‚   â”œâ”€â”€ security/            # Security features
â”‚   â””â”€â”€ storage/             # Database helpers
â”‚
â”œâ”€â”€ frontend/                 # Web UI (HTML/JS)
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ login.html
â”‚   â”œâ”€â”€ transcripts.html
â”‚   â””â”€â”€ assets/
â”‚
â”œâ”€â”€ clients/                  # Client applications
â”‚   â””â”€â”€ even-demo-app/       # Flutter smart glasses app
â”‚
â”œâ”€â”€ models/                   # ML models (gitignored)
â”‚   â””â”€â”€ gemma-3-4b-it-*.gguf
â”‚
â”œâ”€â”€ docker/gateway_instance/  # Gateway runtime data (gitignored)
â”‚   â”œâ”€â”€ users.db             # User database
â”‚   â”œâ”€â”€ enrollment/          # Speaker audio samples
â”‚   â”œâ”€â”€ uploads/             # Uploaded audio/files
â”‚   â””â”€â”€ cache/               # Temporary/cache data
â”‚
â”œâ”€â”€ docker/rag_instance/      # RAG runtime data (gitignored)
â”‚   â””â”€â”€ rag.db               # Memory database (created by service)
â”‚
â”œâ”€â”€ docker/faiss_index/       # Vector index store (gitignored)
â”‚   â”œâ”€â”€ index.bin            # FAISS index
â”‚   â””â”€â”€ *.docs               # Metadata files
â”‚
â”œâ”€â”€ logs/                     # Application logs (gitignored)
â”œâ”€â”€ scripts/                  # Utility scripts
â””â”€â”€ tests/                    # Test suites
```

---

## ğŸ“– Documentation

### Service Documentation
Each service has detailed documentation:
- [API Gateway](services/api-gateway/README.md) - Authentication & routing
- [Transcription Service](services/transcription-service/README.md) - Speech-to-text
- [Emotion Service](services/emotion-service/README.md) - Sentiment analysis
- [RAG Service](services/rag-service/README.md) - Semantic search
- [Gemma Service](services/gemma-service/README.md) - AI chat
- [GPU Coordinator](services/queue-service/README.md) - GPU management

### API Examples

#### Transcribe Audio
```bash
curl -X POST http://localhost:8000/api/transcribe \
  -H "Cookie: session_id=YOUR_SESSION" \
  -F "audio=@recording.wav" \
  -F "enable_diarization=true" \
  -F "enable_emotion=true"
```

#### Semantic Search
```bash
curl -X POST http://localhost:8000/api/rag/search \
  -H "Cookie: session_id=YOUR_SESSION" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "what did they say about the budget?",
    "top_k": 5,
    "last_n_transcripts": 10
  }'
```

#### Chat with AI
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Cookie: session_id=YOUR_SESSION" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Summarize today's meeting"}
    ],
    "use_rag": true,
    "max_tokens": 500
  }'
```

---

## ğŸ”§ Configuration

### Environment Variables

Key variables in `docker/.env`:

```bash
# Service URLs (internal)
GEMMA_URL=http://gemma-service:8001
RAG_URL=http://rag-service:8004
EMOTION_URL=http://emotion-service:8005
TRANSCRIPTION_URL=http://transcription-service:8003

# Security
JWT_ONLY=true
SESSION_COOKIE_SECURE=false  # Set true for HTTPS
ALLOWED_ORIGINS=http://localhost,http://127.0.0.1

# Transcription
NEMO_MODEL_NAME=nvidia/parakeet-rnnt-0.6b
ENABLE_PYANNOTE=true
DIARIZATION_SPK_MAX=3

# Gemma AI
GEMMA_MODEL_PATH=/app/models/gemma-3-4b-it-UD-Q4_K_XL.gguf
GEMMA_GPU_LAYERS=25
GEMMA_CONTEXT_SIZE=65536

# RAG
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

### Hardware Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| GPU VRAM | 8GB | 12GB+ |
| System RAM | 16GB | 32GB+ |
| Storage | 20GB | 50GB+ |
| CPU | 4 cores | 8+ cores |

---

## ğŸ§ª Testing

```bash
# Run all tests (unit + smoke + security by default)
./scripts/run_tests.sh

# Unit tests only
pytest -m unit -v

# Integration tests (requires services running; opt-in)
RUN_INTEGRATION=1 pytest -m integration -v

# Smoke tests (gateway health)
pytest -m smoke -v
```

---

## ğŸ› ï¸ Development

### Running Services Individually

```bash
# API Gateway
cd services/api-gateway
uvicorn src.main:app --reload --port 8000

# Transcription Service
cd services/transcription-service
uvicorn src.main:app --reload --port 8003

# etc.
```

### Debugging

```bash
# View logs
docker compose logs -f api-gateway

# Check GPU usage
nvidia-smi -l 1

# Redis CLI
docker exec -it refactored_redis redis-cli

# PostgreSQL CLI
docker exec -it refactored_postgres psql -U nemo_user nemo_queue
```

---

## ğŸ“Š Monitoring

### Health Checks
```bash
# All services
curl http://localhost:8000/health
curl http://localhost:8001/health
curl http://localhost:8003/health
curl http://localhost:8004/health
curl http://localhost:8005/health
curl http://localhost:8002/health
```

### Metrics
- GPU utilization: `nvidia-smi`
- Service logs: `docker compose logs`
- Redis: `redis-cli INFO`
- PostgreSQL: `psql` queries

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

See `.github/PULL_REQUEST_TEMPLATE.md` for PR guidelines.

---

## ğŸ“„ License

This project includes third-party components:
- **NeMo**: Apache 2.0 License
- **Gemma Models**: Gemma Terms of Use
- **Transformers**: Apache 2.0 License
- **FAISS**: MIT License

---

## ğŸ™ Acknowledgments

- **NVIDIA NeMo**: State-of-the-art ASR models
- **Google**: Gemma 3 language model
- **Hugging Face**: Model hosting and transformers
- **llama.cpp**: Efficient LLM inference
- **Even Realities**: Smart glasses platform inspiration

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/pruittcolon/NeMo_Server/issues)
- **Discussions**: [GitHub Discussions](https://github.com/pruittcolon/NeMo_Server/discussions)

---

**Built with â¤ï¸ for the future of conversational AI**
